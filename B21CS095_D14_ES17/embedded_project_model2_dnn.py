# -*- coding: utf-8 -*-
"""Embedded_project_MODEL2_DNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mRzM4SOnNZV2PLP5HEPlzAUGVtYAvjRk

## Importing the required libraries and loading data
"""

!pip install -U -q tensorflow tensorflow_datasets
!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2

import tensorflow as tf

from tensorflow.keras import layers
from tensorflow.keras import models
from IPython import display
from sklearn.model_selection import train_test_split

import os
import pathlib
import librosa
import json

import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

DATASET_PATH = 'data/mini_speech_commands'

data_dir = pathlib.Path(DATASET_PATH)
if not data_dir.exists():
  tf.keras.utils.get_file(
      'mini_speech_commands.zip',
      origin="http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip",
      extract=True,
      cache_dir='.', cache_subdir='data')

"""## data-preprocessing"""

DATASET_PATH = 'data/mini_speech_commands'
JSON_PATH = "data.json"
SAMPLES_TO_CONSIDER = 22050  # 1 second of audio

def extract_features(file_path, samples_to_consider=SAMPLES_TO_CONSIDER):
    signal, sample_rate = librosa.load(file_path)

    if len(signal) >= samples_to_consider:
        signal = signal[:samples_to_consider]

        num_mfcc = 13
        n_fft = 2048
        hop_length = 512
        MFCCs = librosa.feature.mfcc(y=signal, n_mfcc=num_mfcc, hop_length=hop_length, n_fft=n_fft)

        return MFCCs.T.tolist()
    else:
        return None

def preprocess_data(dataset_path, json_path):
    data = {"mapping": [], "labels": [], "MFCCs": [], "files": []}

    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):
        if dirpath is not dataset_path:
            label = dirpath.split("/")[-1]
            data["mapping"].append(label)

            for f in filenames:
                file_path = os.path.join(dirpath, f)
                MFCCs = extract_features(file_path)

                if MFCCs:
                    data["MFCCs"].append(MFCCs)
                    data["labels"].append(i - 1)
                    data["files"].append(file_path)

    with open(json_path, "w") as fp:
        json.dump(data, fp, indent=4)

# Main code
preprocess_data(DATASET_PATH, JSON_PATH)

"""## Training and test of data"""

DATA_PATH = "data.json"
JSON_PATH = "data.json"

# Define prepare_dataset function
def prepare_dataset(data_path, test_size=0.2, validation_size=0.2):
    try:
        # Load dataset
        with open(data_path, "r") as fp:
            data = json.load(fp)

        # Extract features and labels
        X = np.array(data["MFCCs"])
        y = np.array(data["labels"])

        # Print information
        print("Dataset loaded.")

        # Create train-test split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

        # Further split train set into train-validation sets
        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size, random_state=42)

        # Reshape arrays to include channel dimension
        X_train = X_train[..., np.newaxis]
        X_test = X_test[..., np.newaxis]
        X_validation = X_validation[..., np.newaxis]

        return X_train, y_train, X_validation, y_validation, X_test, y_test

    except Exception as e:
        print("Error occurred while preparing dataset:", str(e))
        return None, None, None, None, None, None

# Call prepare_dataset function
X_train, y_train, X_validation, y_validation, X_test, y_test = prepare_dataset(DATA_PATH)

# Check if the dataset is loaded successfully
if X_train is not None:
    print("Train set shape:", X_train.shape)
    print("Validation set shape:", X_validation.shape)
    print("Test set shape:", X_test.shape)
else:
    print("Dataset loading failed. Please check the data path.")

"""## Model Training & testing

### DNN Model
"""

def build_dnn(input_shape, num_classes, loss="sparse_categorical_crossentropy", learning_rate=0.001):
    try:
        # Initialize a sequential model
        model = tf.keras.models.Sequential()

        # Add convolutional layers
        model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))
        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
        model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))
        model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))

        # Flatten the output
        model.add(tf.keras.layers.Flatten())

        # Add dense layers with dropout
        model.add(tf.keras.layers.Dense(256, activation='relu'))
        model.add(tf.keras.layers.Dropout(0.5))
        model.add(tf.keras.layers.Dense(128, activation='relu'))
        model.add(tf.keras.layers.Dropout(0.3))
        model.add(tf.keras.layers.Dense(64, activation='relu'))
        model.add(tf.keras.layers.Dropout(0.3))

        # Add output layer with softmax activation
        model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))

        # Define optimizer
        optimizer = tf.optimizers.Adam(learning_rate=learning_rate)

        # Compile the model
        model.compile(optimizer=optimizer, loss=loss, metrics=["accuracy"])

        # Print model summary
        model.summary()

        return model

    except Exception as e:
        print("An error occurred while building the DNN model:", str(e))
        return None

# Define input shape and number of classes
input_shape = (X_train.shape[1], X_train.shape[2], 1)
num_classes = len(np.unique(y_train))

# Build the DNN model
model = build_dnn(input_shape, num_classes, learning_rate=0.001)

EPOCHS = 40
BATCH_SIZE = 16
PATIENCE = 5

def train(model, epochs, batch_size, patience, X_train, y_train, X_validation, y_validation):
    try:
        # Define early stopping callback
        earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor="val_accuracy", min_delta=0.001, patience=patience, restore_best_weights=True)

        # Train the model
        history = model.fit(X_train, y_train,
                            epochs=epochs,
                            batch_size=batch_size,
                            validation_data=(X_validation, y_validation),
                            callbacks=[earlystop_callback])

        return history

    except Exception as e:
        print("An error occurred during training:", str(e))
        return None

# Train the network
history = train(model, EPOCHS, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)

import matplotlib.pyplot as plt

def plot_history(history):
    try:
        # Create figure and axes
        fig, axs = plt.subplots(2)

        # Plot accuracy
        axs[0].plot(history.history["accuracy"], label="Training Accuracy")
        axs[0].plot(history.history['val_accuracy'], label="Validation Accuracy")
        axs[0].set_ylabel("Accuracy")
        axs[0].set_title("Accuracy Evaluation")
        axs[0].legend(loc="lower right")

        # Plot loss
        axs[1].plot(history.history["loss"], label="Training Loss")
        axs[1].plot(history.history['val_loss'], label="Validation Loss")
        axs[1].set_xlabel("Epoch")
        axs[1].set_ylabel("Loss")
        axs[1].set_title("Loss Evaluation")
        axs[1].legend(loc="upper right")

        # Adjust layout
        plt.tight_layout()

        # Show plot
        plt.show()

    except Exception as e:
        print("An error occurred while plotting history:", str(e))

# Plot accuracy/loss for training/validation set
plot_history(history)

# Evaluate network on test set
def evaluate_model(model, X_test, y_test):
    try:
        # Evaluate the model
        test_loss, test_acc = model.evaluate(X_test, y_test)

        # Print the evaluation results
        print("\nTest Loss:", test_loss)
        print("Test Accuracy:", test_acc * 100, "%")

    except Exception as e:
        print("An error occurred during evaluation:", str(e))

# Call the evaluate_model function
evaluate_model(model, X_test, y_test)

"""## Experiment with different Learning rate"""

from tabulate import tabulate

# Array of different values of learning rate
lr_array = [0.00001, 0.0001, 0.001, 0.01, 0.1]
result = []

for lr in lr_array:
    print(f"\nTraining model with learning rate: {lr}")
    temp = []
    model = build_dnn(input_shape, learning_rate=lr, num_classes=8)
    history = train(model, EPOCHS, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)
    test_loss, test_acc = model.evaluate(X_test, y_test)
    print(f"Test loss with learning rate {lr}: {test_loss}, Test accuracy: {test_acc}")
    temp.extend([lr, test_loss, test_acc])
    result.append(temp)

# Create header
head = ["Learning Rate", "Test Loss", "Test Accuracy"]

# Display table
print(tabulate(result, headers=head, tablefmt="grid"))

"""## Experiment with different Batch Size"""

from tabulate import tabulate
import matplotlib.pyplot as plt

LEARNING_RATE = 0.001
# Array of different values of batch size
batch_array = [16, 32, 64, 128, 256]
result1 = []

for batch_size in batch_array:
    print(f"\nTraining model with batch size: {batch_size}")
    temp = []
    model = build_dnn(input_shape, learning_rate=LEARNING_RATE, num_classes=8)
    history = train(model, EPOCHS, batch_size, PATIENCE, X_train, y_train, X_validation, y_validation)
    test_loss, test_acc = model.evaluate(X_test, y_test)
    print(f"Test loss with batch size {batch_size}: {test_loss}, Test accuracy: {test_acc}")
    temp.extend([batch_size, test_loss, test_acc])
    result1.append(temp)

# Create header
head1 = ["Batch Size", "Test Loss", "Test Accuracy"]

# Display table
print(tabulate(result1, headers=head1, tablefmt="grid"))

# Plotting test loss and accuracy for each batch size
batch_sizes = [row[0] for row in result1]
test_losses = [row[1] for row in result1]
test_accuracies = [row[2] for row in result1]

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(batch_sizes, test_losses, marker='o')
plt.title('Test Loss vs Batch Size')
plt.xlabel('Batch Size')
plt.ylabel('Test Loss')

plt.subplot(1, 2, 2)
plt.plot(batch_sizes, test_accuracies, marker='o')
plt.title('Test Accuracy vs Batch Size')
plt.xlabel('Batch Size')
plt.ylabel('Test Accuracy')

plt.tight_layout()
plt.show()

"""## Experiment with different Epoch value"""

from tabulate import tabulate
import matplotlib.pyplot as plt

# Array of different values of epochs
epoch_array = [20, 30, 40, 50, 60]
result2 = []

for epochs in epoch_array:
    print(f"\nTraining model with {epochs} epochs")
    temp = []
    model = build_dnn(input_shape, learning_rate=LEARNING_RATE, num_classes=8)
    history = train(model, epochs, BATCH_SIZE, PATIENCE, X_train, y_train, X_validation, y_validation)
    test_loss, test_acc = model.evaluate(X_test, y_test)
    print(f"Test loss with {epochs} epochs: {test_loss}, Test accuracy: {test_acc}")
    temp.extend([epochs, test_loss, test_acc])
    result2.append(temp)

# Create header
head2 = ["Epoch", "Test Loss", "Test Accuracy"]

# Display table
print(tabulate(result2, headers=head2, tablefmt="grid"))

# Plotting test loss and accuracy for each number of epochs
epochs_values = [row[0] for row in result2]
test_losses = [row[1] for row in result2]
test_accuracies = [row[2] for row in result2]

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs_values, test_losses, marker='o')
plt.title('Test Loss vs Epochs')
plt.xlabel('Epochs')
plt.ylabel('Test Loss')

plt.subplot(1, 2, 2)
plt.plot(epochs_values, test_accuracies, marker='o')
plt.title('Test Accuracy vs Epochs')
plt.xlabel('Epochs')
plt.ylabel('Test Accuracy')

plt.tight_layout()
plt.show()

"""## Experiment with different PATIENCE VALUE"""

from tabulate import tabulate
import matplotlib.pyplot as plt

# Array of different values of patience
patience_array = [3, 4, 5, 6, 7]
result3 = []

for patience in patience_array:
    print(f"\nTraining model with patience={patience}")
    temp = []
    model = build_dnn(input_shape, learning_rate=LEARNING_RATE, num_classes=8)
    history = train(model, EPOCHS, BATCH_SIZE, patience, X_train, y_train, X_validation, y_validation)
    test_loss, test_acc = model.evaluate(X_test, y_test)
    print(f"Test loss with patience={patience}: {test_loss}, Test accuracy: {test_acc}")
    temp.extend([patience, test_loss, test_acc])
    result3.append(temp)

# Create header
head3 = ["Patience", "Test Loss", "Test Accuracy"]

# Display table
print(tabulate(result3, headers=head3, tablefmt="grid"))

# Plotting test loss and accuracy for each value of patience
patience_values = [row[0] for row in result3]
test_losses = [row[1] for row in result3]
test_accuracies = [row[2] for row in result3]

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(patience_values, test_losses, marker='o')
plt.title('Test Loss vs Patience')
plt.xlabel('Patience')
plt.ylabel('Test Loss')

plt.subplot(1, 2, 2)
plt.plot(patience_values, test_accuracies, marker='o')
plt.title('Test Accuracy vs Patience')
plt.xlabel('Patience')
plt.ylabel('Test Accuracy')

plt.tight_layout()
plt.show()